(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{542:function(e,o,t){"use strict";t.r(o);var n=t(1),s=Object(n.a)({},(function(){var e=this,o=e.$createElement,t=e._self._c||o;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"hadoop-resource-integration"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-resource-integration"}},[e._v("#")]),e._v(" Hadoop Resource Integration")]),e._v(" "),t("p",[e._v("To use Hadoop resources under StreamX Flink-K8s runtime, such as checkpoint mounting HDFS, accessing Hive, etc.  Users need to build the relevant Flink Base Docker Image by themselves. The Image needs to contain the following contentï¼š")]),e._v(" "),t("ul",[t("li",[e._v("Include Hadoop Lib resource, and set "),t("code",[e._v("HADOOP_CLASSPATH")]),e._v("ï¼›")]),e._v(" "),t("li",[e._v("Include Hadoop Config resourceï¼Œand set "),t("code",[e._v("HADOOP_CONF_DIR")]),e._v("ï¼›")]),e._v(" "),t("li",[e._v("Include  Hive Config Resource when using Hive;")])]),e._v(" "),t("br"),e._v(" "),t("p",[e._v("This is actually quite inconvenient ðŸ¥², we will support automatic integration of Hadoop features in subsequent releases, Plz look forward to !")])])}),[],!1,null,null,null);o.default=s.exports}}]);