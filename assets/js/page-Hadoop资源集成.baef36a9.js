(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{566:function(o,t,e){"use strict";e.r(t);var a=e(1),n=Object(a.a)({},(function(){var o=this,t=o.$createElement,e=o._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":o.$parent.slotKey}},[e("h2",{attrs:{id:"在-k8s-上使用-hadoop-资源"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#在-k8s-上使用-hadoop-资源"}},[o._v("#")]),o._v(" 在 K8s 上使用 Hadoop 资源")]),o._v(" "),e("p",[o._v("在 StreamX Flink-K8s runtime 下使用 Hadoop 资源，如 checkpoint 挂载 HDFS、读写 Hive 等，目前用户需要自行构建相关 Flink Base   Docker Image，Image 中需要包含以下内容：")]),o._v(" "),e("ul",[e("li",[o._v("包含 Hadoop Lib， 并设置 "),e("code",[o._v("HADOOP_CLASSPATH")]),o._v(" 到该目录；")]),o._v(" "),e("li",[o._v("包含 Hadoop Config，并设置 "),e("code",[o._v("HADOOP_CONF_DIR")]),o._v(" 到该目录；")]),o._v(" "),e("li",[o._v("如果使用 Hive， 需要包含 Hive Config；")])]),o._v(" "),e("br"),o._v(" "),e("p",[o._v("这其实挺不优雅的 🥲，我们将在随后的版本里支持"),e("strong",[o._v("自动集成 Hadoop")]),o._v(" 的功能支持， Plz look forward to !")])])}),[],!1,null,null,null);t.default=n.exports}}]);